from __future__ import annotations
import logging
import httpx
import config
# logic.py

# ---- URL & HTTP helpers (autogenerated for 2.7.3) ----
log = logging.getLogger("tustus.logic")

def _get_source_url() -> str:
    return config.URL

def _http_get(url: str) -> str:
    r = httpx.get(
        url,
        timeout=getattr(config, "REQUEST_TIMEOUT", 15),
        headers={"User-Agent": getattr(config, "USER_AGENT", "Mozilla/5.0")},
    )
    r.raise_for_status()
    return r.text

def fetch_flights_html() -> str:
    url = _get_source_url()
    log.info("ğŸ“¡ Fetching from URL=%s", url)
    return _http_get(url)


__file_version__ = "tustus_2.5.10a"  # updated 2025-08-30 18:58  # added 2025-08-30 18:21
import logging, re, hashlib, json, urllib.parse, pathlib
import httpx
from typing import List, Dict, Any, Optional
from datetime import datetime


def _get_source_url() -> str:
    return config.URL

def _http_get(url: str) -> str:
    r = None  # replaced by fetch_flights_html(),
                  headers={"User-Agent": getattr(config, "USER_AGENT", "Mozilla/5.0")})
    r.raise_for_status()
    return r.text

def fetch_flights_html() -> str:
    url = _get_source_url()
    log.info("ğŸ“¡ Fetching from URL=%s", url)
    return _http_get(url)


import requests
from bs4 import BeautifulSoup
import config as cfg

logger = logging.getLogger("tustus.logic")

UA        = getattr(cfg, "USER_AGENT", "Mozilla/5.0")
TIMEOUT   = int(getattr(cfg, "REQUEST_TIMEOUT", 20))
USD_TO_ILS = 3.7  # unused for display

def _clean(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").replace("\xa0", " ")).strip()

def _join_url(base: str, cand: str) -> str:
    if not cand: return ""
    cand = cand.strip()
    if cand.startswith("//"):
        return (urllib.parse.urlparse(base).scheme or "https") + ":" + cand
    if re.match(r"^https?://", cand, re.I):
        return cand
    return urllib.parse.urljoin(base, cand)

def _int(x) -> Optional[int]:
    if x is None: return None
    try: return int(x)
    except Exception:
        try: return int(float(str(x).replace(",", "")))
        except Exception: return None

def _price_to_ils(amount: Optional[int|float], currency: str) -> Optional[int]:
    if amount is None: return None
    c = (currency or "ILS").upper()
    if c in ("ILS", "â‚ª", "NIS"): return int(round(float(amount)))
    if c in ("USD", "$"):        return int(round(float(amount) * USD_TO_ILS))
    # ××˜×‘×¢ ××—×¨? ×ª×©××™×¨×™ ×›××• ×©×”×•× (××• ×”×•×¡×™×¤×™ ××™×¤×•×™)
    return int(round(float(amount)))

def _parse_brand_datetimes(brand: str) -> tuple[Optional[datetime], Optional[datetime]]:
    """
    data_ga_item_brand × ×¨××” ×›××•:
    '9/2/2025 6:00:00 PM-8/29/2025 7:30:00 AM'
    × ×—×–×™×¨ (min_dt, max_dt) â€” ×™×¦×™××”/×—×–×¨×” ×œ×¤×™ ×›×¨×•× ×•×œ×•×’×™×”.
    """
    if not brand: return (None, None)
    parts = [p.strip() for p in str(brand).split("-") if p.strip()]
    fmt = "%m/%d/%Y %I:%M:%S %p"
    dts: list[datetime] = []
    for p in parts:
        try:
            dts.append(datetime.strptime(p, fmt))
        except Exception:
            pass
    if not dts: return (None, None)
    dts.sort()
    go = dts[0]
    back = dts[1] if len(dts) > 1 else None
    return (go, back)

def _norm_ddmm(d: str, year_hint: int|None) -> Optional[str]:
    # "29/08" â†’ YYYY-08-29 (×¢× year_hint ×× × ×™×ª×Ÿ, ××—×¨×ª ×”×©× ×” ×”× ×•×›×—×™×ª/×”×‘××”)
    m = re.match(r"^\s*(\d{2})/(\d{2})\s*$", d or "")
    if not m: return None
    day, month = int(m.group(1)), int(m.group(2))
    y = year_hint or datetime.now().year
    try:
        dt = datetime(y, month, day)
        # ×× ×”×ª××¨×™×š ×›×‘×¨ â€œ×¢×‘×¨â€ ×‘×—×•×“×©×™× ××—×•×¨×” ×•×–×” ×“×™×œ ×¢×ª×™×“×™, ×§×¤×•×¥ ×œ×©× ×” ×”×‘××”
        if dt < datetime.now():
            dt2 = datetime(y + 1, month, day)
            # × ×¢×“×™×£ ×©× ×” ×©×‘×” ×–×” ×ª×•×× ×‘×™×Ÿ brand ×œ-DD/MMâ€”××›×™×•×•×Ÿ ×©×™×© ×œ× ×• brand × ×©×ª××© ×‘×• ×‘× ×¤×¨×“.
            return dt.strftime("%Y-%m-%d")
        return dt.strftime("%Y-%m-%d")
    except Exception:
        return None

def _extract_seats(txt: str) -> Optional[int]:
    # "2 ××§×•××•×ª ××—×¨×•× ×™×" â†’ 2
    m = re.search(r"(\d+)\s*(?:××§×•×|××§×•××•×ª)", txt or "")
    return _int(m.group(1)) if m else None

def _parse_show_item(div, base_url: str) -> Optional[Dict[str, Any]]:
    # --- ××–×”×™× ×•×›×•×ª×¨×•×ª ---
    item_id   = (div.get("ite_item") or "").strip()
    sel_id    = (div.get("ite_selappitem") or "").strip()
    con_desc  = _clean(div.get("con_desc") or div.get("data_ga_item_name") or "")
    title_el  = div.select_one(".show_item_name")
    title_txt = _clean(title_el.get_text(" ", strip=True)) if title_el else ""
    # ×™×¢×“: ×¢×“×™×£ con_desc. ×× ×¨×™×§, × ×—×œ×¥ ××”×›×•×ª×¨×ª "×˜×™×¡×” ×œ..."
    dest = con_desc or re.sub(r"^×˜×™×¡×” ×œ", "", title_txt).strip()
    if not dest:
        return None

    # --- ××—×™×¨ ×•××˜×‘×¢ ---
    price_num = _int(div.get("data_number_ga_price") or "")
    currency  = (div.get("data_ga_currency") or "ILS").strip()
    price_ils = _price_to_ils(price_num, currency)

    # --- ××•×©×‘×™× ---
    seats_block = div.select_one(".spcial_message_bottom")
    seats_txt   = _clean(seats_block.get_text(" ", strip=True)) if seats_block else ""
    seats       = _extract_seats(seats_txt)

    # --- ×ª××¨×™×›×™× (×©×•×¨×ª ×”×¡×™×›×•× + brand ×¢× ×©× ×” ×•×©×¢×”) ---
    brand = div.get("data_ga_item_brand") or ""
    go_dt_brand, back_dt_brand = _parse_brand_datetimes(brand)

    # ×“×•×’××: "×™×•× ×•' 29/08 -  ×™×•× ×’' 02/09"
    summary_line = ""
    details = div.select_one(".show_item_details")
    if details:
        # ×§×— ××ª ×”×˜×§×¡×˜ ×”×¨×¦×™×£
        summary_line = _clean(details.get_text(" ", strip=True))
    ddmm = re.findall(r"\b(\d{2}/\d{2})\b", summary_line)
    go_date = _norm_ddmm(ddmm[0], go_dt_brand.year if go_dt_brand else None) if ddmm else None
    back_date = _norm_ddmm(ddmm[1], back_dt_brand.year if back_dt_brand else None) if len(ddmm) > 1 else None

    # ×× ×™×© brand ××œ××™× â€” × ×¢×“×™×£ ××•×ª× ×œ×§×‘×™×¢×ª ×™×•×/×—×•×“×©/×©× ×”, ×•× ×©××•×¨ ×’× ×©×¢×•×ª ×”×“×™×•×§
    go_depart = go_arrive = back_depart = back_arrive = None

    go_from_t  = div.select_one(".flight_go .from .flight_hourTime")
    go_to_t    = div.select_one(".flight_go .to .flight_hourTime")
    back_from_t= div.select_one(".flight_back .from .flight_hourTime")
    back_to_t  = div.select_one(".flight_back .to .flight_hourTime")

    go_depart  = _clean(go_from_t.get_text(strip=True)) if go_from_t else None
    go_arrive  = _clean(go_to_t.get_text(strip=True)) if go_to_t else None
    back_depart= _clean(back_from_t.get_text(strip=True)) if back_from_t else None
    back_arrive= _clean(back_to_t.get_text(strip=True)) if back_to_t else None

    # ×× ××™×Ÿ go_date/back_date â€“ × ×©×ª××© ×‘-brand ×‘×œ×‘×“
    if go_dt_brand and not go_date:
        go_date = go_dt_brand.strftime("%Y-%m-%d")
        if not go_depart:
            go_depart = go_dt_brand.strftime("%H:%M")
    if back_dt_brand and not back_date:
        back_date = back_dt_brand.strftime("%Y-%m-%d")
        if not back_depart:
            back_depart = back_dt_brand.strftime("%H:%M")

    # ×“×¨×™×©×ª ××™× ×™××•×: ×™×¢×“ + ×ª××¨×™×š ×™×¦×™××”
    if not go_date:
        return None

    # --- ×œ×™× ×§: ×× ××™×Ÿ <a>, × ×™×¦×•×¨ ×§×™×©×•×¨ ×™×¦×™×‘ ×¢× ××–×”×” ---
    link_el = div.select_one("a[href]")
    link = _join_url(base_url, link_el["href"]) if link_el else f"{base_url}?item={item_id or sel_id}"

    # --- ×’×™×‘×•×© ×¤×¨×™×˜ ---
    it = {
        "name": f"âœˆï¸ ×˜×™×¡×” ×œ{dest}",
        "destination": dest,
        "link": link,
        "price": price_ils,
        "go_date": go_date,
        "go_depart": go_depart,
        "go_arrive": go_arrive,
        "back_date": back_date,
        "back_depart": back_depart,
        "back_arrive": back_arrive,
        "seats": seats,
    }
    return it

def _parse_show_items_from_html(html: str, base_url: str) -> List[Dict[str, Any]]:
    soup = BeautifulSoup(html, "lxml")
    cards = soup.select("div.show_item")
    items: List[Dict[str, Any]] = []
    for div in cards:
        it = _parse_show_item(div, base_url)
        if it:
            items.append(it)
    # ×“×”-×“×•×¤
    uniq = {}
    for it in items:
        k = (it["destination"], it["go_date"], it.get("back_date") or "", it.get("price") or 0)
        uniq.setdefault(k, it)
    out = list(uniq.values())
    logger.info(f"show_item cards parsed: {len(out)}")
    return out

def monitor_job(context):
    html = fetch_flights_html()
    app = context.application
    conn = app.bot_data.get("conn")
    base_url = (getattr(cfg, "URL", "") or "").strip()
    if not base_url:
        logger.warning("URL missing in config.py; skipping")
        return

    ses = requests.Session()
    ses.headers.update({"User-Agent": UA, "Accept-Language": "he-IL,he;q=0.9,en;q=0.7"})
    try:
        r = ses.get(base_url, timeout=TIMEOUT)
        r.raise_for_status()
        pathlib.Path("./_debug_tustus.html").write_text(r.text, encoding="utf-8")
    except Exception as e:
        logger.warning(f"scrape_fail: {e}")
        return

    # 1) ×§×•×“× ×›×œ â€” ×”×¤×¨×¡×¨ ×”×™×™×¢×•×“×™ ×œ-show_item
    items = _parse_show_items_from_html(r.text, base_url)

    # 2) ×× ×œ× ××¦× ×›×œ×•×, × ×•×•×ª×¨ â€” ×œ× × ×›× ×™×¡ â€œ×–×‘×œâ€ ×××§×•×¨×•×ª ××—×¨×™×
    if not items:
        snippet = _clean(r.text[:600])
        logger.warning(f"scrape_ok but no items parsed (show_item only) | snippet='{snippet}'")
        return

    # 3) upsert ×œ-DB
    ins = upd = 0
    for it in items:
        dest = it["destination"]
        go   = it["go_date"]
        back = it.get("back_date") or ""
        key  = hashlib.sha1(f"{dest}|{go}|{back}|{it.get('price') or ''}".encode("utf-8")).hexdigest()[:16]

        row = conn.execute("""
            SELECT flight_key FROM flights
            WHERE destination=? AND COALESCE(go_date,'')=? AND COALESCE(back_date,'')=?
            LIMIT 1
        """, (dest, go, back)).fetchone()

        if row:
            conn.execute("""
                UPDATE flights
                SET name=?, link=?, price=?, go_depart=?, go_arrive=?, back_depart=?, back_arrive=?, seats=?, scraped_at=datetime('now')
                WHERE flight_key=?
            """, (it["name"], it["link"], it["price"], it.get("go_depart"), it.get("go_arrive"),
                  it.get("back_depart"), it.get("back_arrive"), it.get("seats"), key))
            upd += 1
        else:
            conn.execute("""
                INSERT INTO flights(
                    name, destination, link, price,
                    go_date, go_depart, go_arrive,
                    back_date, back_depart, back_arrive,
                    seats, first_seen, scraped_at, flight_key
                ) VALUES(?,?,?,?,?,?,?,?,?,?,?, datetime('now'), datetime('now'), ?)
            """, (it["name"], dest, it["link"], it.get("price"),
                  go, it.get("go_depart"), it.get("go_arrive"),
                  back, it.get("back_depart"), it.get("back_arrive"),
                  it.get("seats"), key))
            ins += 1
        conn.commit()

    logger.info(f"DB upsert (show_item): inserted={ins}, updated={upd}")
    return {"inserted": ins, "updated": upd}

def enrich_active_time(row: dict):
    from utils import human_duration_since
    if not row:
        return row
    if not row.get("first_seen"):
        row["first_seen"] = row.get("scraped_at")
    row["active_for"] = human_duration_since(row.get("first_seen") or "")
    return row

import inspect as _inspect

async def run_monitor(conn, app):
    """Run one monitor tick by delegating to monitor_job(context).
    Builds a minimal PTB-like context with .application, and falls back to other signatures if needed.
    """
    import inspect, types, logging
    log = logging.getLogger('tustus.logic')
    fn = globals().get('monitor_job')
    if not fn:
        log.error('run_monitor: monitor_job not found in logic.py')
        return
    ctx = types.SimpleNamespace(
        application=app,
        bot=getattr(app, 'bot', None),
        job_queue=getattr(app, 'job_queue', None),
        db_conn=conn,
    )
    try:
        if inspect.iscoroutinefunction(fn):
            try:
                return await fn(ctx)
            except TypeError:
                try:
                    return await fn(app)
                except TypeError:
                    try:
                        return await fn(conn)
                    except TypeError:
                        return await fn(conn, app)
        else:
            try:
                return fn(ctx)
            except TypeError:
                try:
                    return fn(app)
                except TypeError:
                    try:
                        return fn(conn)
                    except TypeError:
                        return fn(conn, app)
    except Exception:
        log.exception('run_monitor: monitor_job raised')
        raise